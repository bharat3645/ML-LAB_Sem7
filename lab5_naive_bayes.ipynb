{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lab 5: Na\u00efve Bayes Classifier\nThis script demonstrates different types of Na\u00efve Bayes classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris, load_breast_cancer, fetch_20newsgroups\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gaussian_naive_bayes():\n    \"\"\"Demonstrate Gaussian Na\u00efve Bayes for continuous data\"\"\"\n    print(\"=\" * 50)\n    print(\"Gaussian Na\u00efve Bayes\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    print(f\"\\nDataset: Iris\")\n    print(f\"Shape: {X.shape}\")\n    print(f\"Classes: {iris.target_names}\")\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Create and train Gaussian Na\u00efve Bayes\n    gnb = GaussianNB()\n    gnb.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = gnb.predict(X_test)\n    \n    # Evaluate\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"\\nAccuracy: {accuracy:.4f}\")\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=iris.target_names,\n                yticklabels=iris.target_names)\n    plt.title('Confusion Matrix - Gaussian Na\u00efve Bayes')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.tight_layout()\n    plt.savefig('lab5_gaussian_nb_confusion.png')\n    plt.close()\n    print(\"\\nConfusion matrix saved as 'lab5_gaussian_nb_confusion.png'\")\n    \n    # Print class probabilities\n    print(\"\\nClass prior probabilities:\")\n    for i, prob in enumerate(gnb.class_prior_):\n        print(f\"{iris.target_names[i]}: {prob:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multinomial_naive_bayes():\n    \"\"\"Demonstrate Multinomial Na\u00efve Bayes for text classification\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Multinomial Na\u00efve Bayes (Text Classification)\")\n    print(\"=\" * 50)\n    \n    # Create sample text data\n    texts = [\n        \"I love machine learning\",\n        \"Python is great for data science\",\n        \"Deep learning is fascinating\",\n        \"I enjoy coding in Python\",\n        \"Machine learning is powerful\",\n        \"Data science is my passion\",\n        \"I hate spam emails\",\n        \"This is unwanted message\",\n        \"Get free money now\",\n        \"Spam spam spam\",\n        \"Unwanted advertisement here\",\n        \"Click here for prize\"\n    ]\n    \n    labels = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]  # 0: legitimate, 1: spam\n    \n    print(f\"\\nSample size: {len(texts)}\")\n    print(f\"Classes: Legitimate (0), Spam (1)\")\n    \n    # Convert text to features\n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    \n    print(f\"Feature matrix shape: {X.shape}\")\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, labels, test_size=0.25, random_state=42\n    )\n    \n    # Train Multinomial Na\u00efve Bayes\n    mnb = MultinomialNB()\n    mnb.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = mnb.predict(X_test)\n    \n    # Evaluate\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"\\nAccuracy: {accuracy:.4f}\")\n    \n    # Test with new samples\n    new_texts = [\"I love data science\", \"Free prize click now\"]\n    new_X = vectorizer.transform(new_texts)\n    predictions = mnb.predict(new_X)\n    proba = mnb.predict_proba(new_X)\n    \n    print(\"\\nPredictions on new samples:\")\n    for text, pred, prob in zip(new_texts, predictions, proba):\n        label = \"Legitimate\" if pred == 0 else \"Spam\"\n        print(f\"Text: '{text}'\")\n        print(f\"  Prediction: {label}\")\n        print(f\"  Probabilities: Legitimate={prob[0]:.4f}, Spam={prob[1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bernoulli_naive_bayes():\n    \"\"\"Demonstrate Bernoulli Na\u00efve Bayes for binary features\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Bernoulli Na\u00efve Bayes\")\n    print(\"=\" * 50)\n    \n    # Create binary feature data\n    np.random.seed(42)\n    X = np.random.randint(2, size=(100, 5))  # Binary features\n    y = (X[:, 0] + X[:, 1] + X[:, 2] > 1).astype(int)  # Target based on features\n    \n    print(f\"\\nDataset shape: {X.shape}\")\n    print(f\"Binary features (0 or 1)\")\n    print(f\"First 5 samples:\\n{X[:5]}\")\n    print(f\"First 5 labels: {y[:5]}\")\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Train Bernoulli Na\u00efve Bayes\n    bnb = BernoulliNB()\n    bnb.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = bnb.predict(X_test)\n    \n    # Evaluate\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"\\nAccuracy: {accuracy:.4f}\")\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_naive_bayes_types():\n    \"\"\"Compare different Na\u00efve Bayes classifiers\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Comparing Na\u00efve Bayes Types\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    cancer = load_breast_cancer()\n    X = cancer.data\n    y = cancer.target\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Train different classifiers\n    classifiers = {\n        'Gaussian NB': GaussianNB(),\n        'Multinomial NB': MultinomialNB(),\n        'Bernoulli NB': BernoulliNB()\n    }\n    \n    results = {}\n    \n    print(\"\\nResults on Breast Cancer dataset:\")\n    for name, clf in classifiers.items():\n        try:\n            clf.fit(X_train, y_train)\n            accuracy = clf.score(X_test, y_test)\n            results[name] = accuracy\n            print(f\"{name}: {accuracy:.4f}\")\n        except Exception as e:\n            print(f\"{name}: Error - {str(e)}\")\n    \n    # Plot comparison\n    if results:\n        plt.figure(figsize=(10, 6))\n        plt.bar(results.keys(), results.values(), \n                color=['blue', 'green', 'orange'])\n        plt.ylabel('Accuracy')\n        plt.title('Comparison of Na\u00efve Bayes Classifiers')\n        plt.ylim([0.8, 1.0])\n        for i, (name, acc) in enumerate(results.items()):\n            plt.text(i, acc + 0.01, f'{acc:.4f}', ha='center')\n        plt.tight_layout()\n        plt.savefig('lab5_nb_comparison.png')\n        plt.close()\n        print(\"\\nComparison plot saved as 'lab5_nb_comparison.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def naive_bayes_with_cross_validation():\n    \"\"\"Demonstrate Na\u00efve Bayes with cross-validation\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Na\u00efve Bayes with Cross-Validation\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    # Create classifier\n    gnb = GaussianNB()\n    \n    # Perform cross-validation\n    scores = cross_val_score(gnb, X, y, cv=5)\n    \n    print(f\"\\nCross-validation scores: {scores}\")\n    print(f\"Mean accuracy: {scores.mean():.4f}\")\n    print(f\"Standard deviation: {scores.std():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_probability_analysis():\n    \"\"\"Analyze feature probabilities in Na\u00efve Bayes\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Feature Probability Analysis\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    # Train Gaussian Na\u00efve Bayes\n    gnb = GaussianNB()\n    gnb.fit(X, y)\n    \n    # Display learned parameters\n    print(\"\\nClass prior probabilities:\")\n    for i, (class_name, prior) in enumerate(zip(iris.target_names, gnb.class_prior_)):\n        print(f\"{class_name}: {prior:.4f}\")\n    \n    print(\"\\nFeature means per class:\")\n    for i, class_name in enumerate(iris.target_names):\n        print(f\"\\n{class_name}:\")\n        for j, feature_name in enumerate(iris.feature_names):\n            print(f\"  {feature_name}: {gnb.theta_[i, j]:.4f}\")\n    \n    print(\"\\nFeature variances per class:\")\n    for i, class_name in enumerate(iris.target_names):\n        print(f\"\\n{class_name}:\")\n        for j, feature_name in enumerate(iris.feature_names):\n            print(f\"  {feature_name}: {gnb.var_[i, j]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n    \"\"\"Main function to demonstrate Na\u00efve Bayes classifiers\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Lab 5: Na\u00efve Bayes Classifier\")\n    print(\"=\" * 50)\n    \n    # Gaussian Na\u00efve Bayes\n    gaussian_naive_bayes()\n    \n    # Multinomial Na\u00efve Bayes\n    multinomial_naive_bayes()\n    \n    # Bernoulli Na\u00efve Bayes\n    bernoulli_naive_bayes()\n    \n    # Compare types\n    compare_naive_bayes_types()\n    \n    # Cross-validation\n    naive_bayes_with_cross_validation()\n    \n    # Feature probability analysis\n    feature_probability_analysis()\n    \n    print(\"\\n\" + \"=\" * 50)\n    print(\"Lab 5 Complete!\")\n    print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}