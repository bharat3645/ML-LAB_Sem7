{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lab 6: Decision Tree Classifier\nThis script demonstrates Decision Tree classification algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris, load_breast_cancer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def basic_decision_tree():\n    \"\"\"Demonstrate basic Decision Tree classifier\"\"\"\n    print(\"=\" * 50)\n    print(\"Basic Decision Tree Classification\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    print(f\"\\nDataset: Iris\")\n    print(f\"Shape: {X.shape}\")\n    print(f\"Classes: {iris.target_names}\")\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Create and train Decision Tree\n    dt = DecisionTreeClassifier(random_state=42)\n    dt.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = dt.predict(X_test)\n    \n    # Evaluate\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"\\nAccuracy: {accuracy:.4f}\")\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=iris.target_names,\n                yticklabels=iris.target_names)\n    plt.title('Confusion Matrix - Decision Tree')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.tight_layout()\n    plt.savefig('lab6_confusion_matrix.png')\n    plt.close()\n    print(\"\\nConfusion matrix saved as 'lab6_confusion_matrix.png'\")\n    \n    # Feature importance\n    print(\"\\nFeature Importances:\")\n    for name, importance in zip(iris.feature_names, dt.feature_importances_):\n        print(f\"{name}: {importance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_decision_tree():\n    \"\"\"Visualize decision tree structure\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Decision Tree Visualization\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    # Create a simple tree with limited depth\n    dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n    dt.fit(X, y)\n    \n    print(f\"\\nTree depth: {dt.get_depth()}\")\n    print(f\"Number of leaves: {dt.get_n_leaves()}\")\n    \n    # Visualize tree\n    plt.figure(figsize=(20, 10))\n    plot_tree(dt, \n              feature_names=iris.feature_names,\n              class_names=iris.target_names,\n              filled=True,\n              rounded=True,\n              fontsize=10)\n    plt.title('Decision Tree Visualization')\n    plt.tight_layout()\n    plt.savefig('lab6_tree_visualization.png', dpi=100)\n    plt.close()\n    print(\"\\nTree visualization saved as 'lab6_tree_visualization.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tune_hyperparameters():\n    \"\"\"Tune decision tree hyperparameters\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Hyperparameter Tuning\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    cancer = load_breast_cancer()\n    X = cancer.data\n    y = cancer.target\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Test different max_depth values\n    max_depths = range(1, 21)\n    train_scores = []\n    test_scores = []\n    \n    print(\"\\nTesting different max_depth values:\")\n    for depth in max_depths:\n        dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n        dt.fit(X_train, y_train)\n        \n        train_score = dt.score(X_train, y_train)\n        test_score = dt.score(X_test, y_test)\n        \n        train_scores.append(train_score)\n        test_scores.append(test_score)\n        \n        if depth % 5 == 0:\n            print(f\"Depth {depth}: Train={train_score:.4f}, Test={test_score:.4f}\")\n    \n    # Find optimal depth\n    optimal_depth = max_depths[np.argmax(test_scores)]\n    print(f\"\\nOptimal max_depth: {optimal_depth}\")\n    print(f\"Best test accuracy: {max(test_scores):.4f}\")\n    \n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.plot(max_depths, train_scores, 'o-', label='Training Accuracy')\n    plt.plot(max_depths, test_scores, 's-', label='Test Accuracy')\n    plt.axvline(x=optimal_depth, color='r', linestyle='--',\n                label=f'Optimal Depth = {optimal_depth}')\n    plt.xlabel('Max Depth')\n    plt.ylabel('Accuracy')\n    plt.title('Decision Tree: Accuracy vs Max Depth')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('lab6_hyperparameter_tuning.png')\n    plt.close()\n    print(\"\\nHyperparameter tuning plot saved as 'lab6_hyperparameter_tuning.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_criterion():\n    \"\"\"Compare different splitting criteria\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Comparing Splitting Criteria\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Test different criteria\n    criteria = ['gini', 'entropy']\n    results = {}\n    \n    for criterion in criteria:\n        dt = DecisionTreeClassifier(criterion=criterion, random_state=42)\n        dt.fit(X_train, y_train)\n        accuracy = dt.score(X_test, y_test)\n        results[criterion] = accuracy\n        print(f\"\\n{criterion.capitalize()}: {accuracy:.4f}\")\n    \n    # Visualize comparison\n    plt.figure(figsize=(10, 6))\n    plt.bar(results.keys(), results.values(), color=['blue', 'green'])\n    plt.ylabel('Accuracy')\n    plt.title('Decision Tree: Comparison of Splitting Criteria')\n    plt.ylim([0.9, 1.0])\n    for i, (criterion, acc) in enumerate(results.items()):\n        plt.text(i, acc + 0.005, f'{acc:.4f}', ha='center')\n    plt.tight_layout()\n    plt.savefig('lab6_criterion_comparison.png')\n    plt.close()\n    print(\"\\nCriterion comparison saved as 'lab6_criterion_comparison.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_importance_analysis():\n    \"\"\"Analyze feature importances\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Feature Importance Analysis\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    cancer = load_breast_cancer()\n    X = cancer.data\n    y = cancer.target\n    \n    # Train decision tree\n    dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n    dt.fit(X, y)\n    \n    # Get feature importances\n    importances = dt.feature_importances_\n    indices = np.argsort(importances)[::-1]\n    \n    # Print top 10 features\n    print(\"\\nTop 10 Most Important Features:\")\n    for i in range(min(10, len(indices))):\n        print(f\"{i+1}. {cancer.feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n    \n    # Plot feature importances\n    plt.figure(figsize=(12, 6))\n    plt.bar(range(10), importances[indices[:10]])\n    plt.xticks(range(10), [cancer.feature_names[i] for i in indices[:10]], \n               rotation=45, ha='right')\n    plt.xlabel('Features')\n    plt.ylabel('Importance')\n    plt.title('Top 10 Feature Importances')\n    plt.tight_layout()\n    plt.savefig('lab6_feature_importance.png')\n    plt.close()\n    print(\"\\nFeature importance plot saved as 'lab6_feature_importance.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pruning_demonstration():\n    \"\"\"Demonstrate pruning effects\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Pruning Demonstration\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Tree without pruning\n    dt_no_prune = DecisionTreeClassifier(random_state=42)\n    dt_no_prune.fit(X_train, y_train)\n    \n    # Tree with pruning (using min_samples_split and min_samples_leaf)\n    dt_pruned = DecisionTreeClassifier(\n        min_samples_split=10,\n        min_samples_leaf=5,\n        random_state=42\n    )\n    dt_pruned.fit(X_train, y_train)\n    \n    print(\"\\nWithout Pruning:\")\n    print(f\"  Tree depth: {dt_no_prune.get_depth()}\")\n    print(f\"  Number of leaves: {dt_no_prune.get_n_leaves()}\")\n    print(f\"  Train accuracy: {dt_no_prune.score(X_train, y_train):.4f}\")\n    print(f\"  Test accuracy: {dt_no_prune.score(X_test, y_test):.4f}\")\n    \n    print(\"\\nWith Pruning:\")\n    print(f\"  Tree depth: {dt_pruned.get_depth()}\")\n    print(f\"  Number of leaves: {dt_pruned.get_n_leaves()}\")\n    print(f\"  Train accuracy: {dt_pruned.score(X_train, y_train):.4f}\")\n    print(f\"  Test accuracy: {dt_pruned.score(X_test, y_test):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_validation():\n    \"\"\"Perform cross-validation on Decision Tree\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Cross-Validation\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    # Create classifier\n    dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n    \n    # Perform cross-validation\n    scores = cross_val_score(dt, X, y, cv=5)\n    \n    print(f\"\\nCross-validation scores: {scores}\")\n    print(f\"Mean accuracy: {scores.mean():.4f}\")\n    print(f\"Standard deviation: {scores.std():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n    \"\"\"Main function to demonstrate Decision Tree classifier\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Lab 6: Decision Tree Classifier\")\n    print(\"=\" * 50)\n    \n    # Basic decision tree\n    basic_decision_tree()\n    \n    # Visualize tree\n    visualize_decision_tree()\n    \n    # Tune hyperparameters\n    tune_hyperparameters()\n    \n    # Compare criteria\n    compare_criterion()\n    \n    # Feature importance\n    feature_importance_analysis()\n    \n    # Pruning\n    pruning_demonstration()\n    \n    # Cross-validation\n    cross_validation()\n    \n    print(\"\\n\" + \"=\" * 50)\n    print(\"Lab 6 Complete!\")\n    print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}