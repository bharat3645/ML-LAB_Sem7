{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lab 10: Logistic Regression\nThis script demonstrates Logistic Regression for binary and multiclass classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_breast_cancer, load_iris, make_classification\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\nimport seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def binary_classification():\n    \"\"\"Demonstrate binary logistic regression\"\"\"\n    print(\"=\" * 50)\n    print(\"Binary Logistic Regression\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    cancer = load_breast_cancer()\n    X = cancer.data\n    y = cancer.target\n    \n    print(f\"\\nDataset: Breast Cancer\")\n    print(f\"Shape: {X.shape}\")\n    print(f\"Classes: {cancer.target_names}\")\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Standardize features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Create and train model\n    log_reg = LogisticRegression(max_iter=10000, random_state=42)\n    log_reg.fit(X_train_scaled, y_train)\n    \n    # Make predictions\n    y_pred = log_reg.predict(X_test_scaled)\n    y_pred_proba = log_reg.predict_proba(X_test_scaled)\n    \n    # Evaluate\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"\\nAccuracy: {accuracy:.4f}\")\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred, target_names=cancer.target_names))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=cancer.target_names,\n                yticklabels=cancer.target_names)\n    plt.title('Confusion Matrix - Logistic Regression')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.tight_layout()\n    plt.savefig('lab10_confusion_matrix.png')\n    plt.close()\n    print(\"\\nConfusion matrix saved as 'lab10_confusion_matrix.png'\")\n    \n    return X_test_scaled, y_test, y_pred_proba\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def roc_curve_analysis(X_test, y_test, y_pred_proba):\n    \"\"\"Analyze ROC curve and AUC\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"ROC Curve Analysis\")\n    print(\"=\" * 50)\n    \n    # Calculate ROC curve\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1])\n    roc_auc = auc(fpr, tpr)\n    \n    print(f\"\\nArea Under Curve (AUC): {roc_auc:.4f}\")\n    \n    # Plot ROC curve\n    plt.figure(figsize=(10, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, \n             label=f'ROC curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('lab10_roc_curve.png')\n    plt.close()\n    print(\"\\nROC curve saved as 'lab10_roc_curve.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multiclass_classification():\n    \"\"\"Demonstrate multiclass logistic regression\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Multiclass Logistic Regression\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    \n    print(f\"\\nDataset: Iris\")\n    print(f\"Shape: {X.shape}\")\n    print(f\"Classes: {iris.target_names}\")\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    # Standardize features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Create and train model\n    log_reg = LogisticRegression(max_iter=10000, random_state=42)\n    log_reg.fit(X_train_scaled, y_train)\n    \n    # Make predictions\n    y_pred = log_reg.predict(X_test_scaled)\n    \n    # Evaluate\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"\\nAccuracy: {accuracy:.4f}\")\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=iris.target_names,\n                yticklabels=iris.target_names)\n    plt.title('Confusion Matrix - Multiclass Logistic Regression')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.tight_layout()\n    plt.savefig('lab10_multiclass_confusion.png')\n    plt.close()\n    print(\"\\nMulticlass confusion matrix saved as 'lab10_multiclass_confusion.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def regularization_comparison():\n    \"\"\"Compare different regularization techniques\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Regularization Comparison (L1 vs L2)\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    cancer = load_breast_cancer()\n    X = cancer.data\n    y = cancer.target\n    \n    # Split and scale\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Test different regularization penalties\n    penalties = ['l1', 'l2', 'none']\n    results = {}\n    \n    for penalty in penalties:\n        if penalty == 'none':\n            log_reg = LogisticRegression(penalty=None, max_iter=10000, random_state=42)\n        else:\n            log_reg = LogisticRegression(\n                penalty=penalty, \n                solver='liblinear' if penalty == 'l1' else 'lbfgs',\n                max_iter=10000, \n                random_state=42\n            )\n        \n        log_reg.fit(X_train_scaled, y_train)\n        accuracy = log_reg.score(X_test_scaled, y_test)\n        results[penalty] = accuracy\n        \n        print(f\"\\n{penalty.upper() if penalty != 'none' else 'No'} Regularization:\")\n        print(f\"  Accuracy: {accuracy:.4f}\")\n        print(f\"  Non-zero coefficients: {np.sum(log_reg.coef_ != 0)}\")\n    \n    # Visualize comparison\n    plt.figure(figsize=(10, 6))\n    plt.bar(results.keys(), results.values(), color=['blue', 'green', 'orange'])\n    plt.ylabel('Accuracy')\n    plt.title('Logistic Regression: Regularization Comparison')\n    plt.ylim([0.9, 1.0])\n    for i, (penalty, acc) in enumerate(results.items()):\n        plt.text(i, acc + 0.005, f'{acc:.4f}', ha='center')\n    plt.tight_layout()\n    plt.savefig('lab10_regularization.png')\n    plt.close()\n    print(\"\\nRegularization comparison saved as 'lab10_regularization.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decision_boundary_visualization():\n    \"\"\"Visualize decision boundary for 2D data\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Decision Boundary Visualization\")\n    print(\"=\" * 50)\n    \n    # Generate 2D dataset\n    X, y = make_classification(\n        n_samples=200,\n        n_features=2,\n        n_redundant=0,\n        n_informative=2,\n        n_clusters_per_class=1,\n        random_state=42\n    )\n    \n    # Standardize\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    # Train model\n    log_reg = LogisticRegression(random_state=42)\n    log_reg.fit(X_scaled, y)\n    \n    print(f\"\\nAccuracy: {log_reg.score(X_scaled, y):.4f}\")\n    \n    # Create mesh for decision boundary\n    h = 0.02\n    x_min, x_max = X_scaled[:, 0].min() - 1, X_scaled[:, 0].max() + 1\n    y_min, y_max = X_scaled[:, 1].min() - 1, X_scaled[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    \n    # Predict on mesh\n    Z = log_reg.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    \n    # Plot\n    plt.figure(figsize=(10, 6))\n    plt.contourf(xx, yy, Z, alpha=0.4, cmap='RdYlBu')\n    plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y, cmap='RdYlBu', \n                edgecolors='black', s=50)\n    plt.xlabel('Feature 1')\n    plt.ylabel('Feature 2')\n    plt.title('Logistic Regression Decision Boundary')\n    plt.colorbar(label='Class')\n    plt.tight_layout()\n    plt.savefig('lab10_decision_boundary.png')\n    plt.close()\n    print(\"\\nDecision boundary saved as 'lab10_decision_boundary.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def probability_analysis():\n    \"\"\"Analyze prediction probabilities\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Prediction Probability Analysis\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    iris = load_iris()\n    X = iris.data[:100]  # Use only first 2 classes\n    y = iris.target[:100]\n    \n    # Split and scale\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42\n    )\n    \n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Train model\n    log_reg = LogisticRegression(max_iter=10000, random_state=42)\n    log_reg.fit(X_train_scaled, y_train)\n    \n    # Get probabilities\n    y_pred_proba = log_reg.predict_proba(X_test_scaled)\n    y_pred = log_reg.predict(X_test_scaled)\n    \n    # Display sample predictions with probabilities\n    print(\"\\nSample Predictions with Probabilities:\")\n    print(f\"{'Actual':<10} {'Predicted':<10} {'Prob Class 0':<15} {'Prob Class 1':<15}\")\n    print(\"-\" * 50)\n    for i in range(min(10, len(y_test))):\n        print(f\"{y_test[i]:<10} {y_pred[i]:<10} {y_pred_proba[i][0]:.4f}{'':<10} {y_pred_proba[i][1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_validation():\n    \"\"\"Perform cross-validation\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Cross-Validation\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    cancer = load_breast_cancer()\n    X = cancer.data\n    y = cancer.target\n    \n    # Standardize\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    # Create model\n    log_reg = LogisticRegression(max_iter=10000, random_state=42)\n    \n    # Perform cross-validation\n    scores = cross_val_score(log_reg, X_scaled, y, cv=5)\n    \n    print(f\"\\nCross-validation scores: {scores}\")\n    print(f\"Mean accuracy: {scores.mean():.4f}\")\n    print(f\"Standard deviation: {scores.std():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_coefficients():\n    \"\"\"Analyze feature coefficients\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Feature Coefficients Analysis\")\n    print(\"=\" * 50)\n    \n    # Load dataset\n    cancer = load_breast_cancer()\n    X = cancer.data\n    y = cancer.target\n    \n    # Standardize\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    # Train model\n    log_reg = LogisticRegression(max_iter=10000, random_state=42)\n    log_reg.fit(X_scaled, y)\n    \n    # Get coefficients\n    coefficients = log_reg.coef_[0]\n    feature_importance = pd.DataFrame({\n        'Feature': cancer.feature_names,\n        'Coefficient': coefficients,\n        'Abs_Coefficient': np.abs(coefficients)\n    }).sort_values('Abs_Coefficient', ascending=False)\n    \n    print(\"\\nTop 10 Most Important Features:\")\n    print(feature_importance.head(10).to_string(index=False))\n    \n    # Plot top features\n    top_features = feature_importance.head(10)\n    plt.figure(figsize=(12, 6))\n    colors = ['green' if c > 0 else 'red' for c in top_features['Coefficient']]\n    plt.barh(range(len(top_features)), top_features['Coefficient'], color=colors)\n    plt.yticks(range(len(top_features)), top_features['Feature'])\n    plt.xlabel('Coefficient Value')\n    plt.title('Top 10 Feature Coefficients (Green: Positive, Red: Negative)')\n    plt.tight_layout()\n    plt.savefig('lab10_feature_coefficients.png')\n    plt.close()\n    print(\"\\nFeature coefficients plot saved as 'lab10_feature_coefficients.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n    \"\"\"Main function to demonstrate logistic regression\"\"\"\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Lab 10: Logistic Regression\")\n    print(\"=\" * 50)\n    \n    # Binary classification\n    X_test, y_test, y_pred_proba = binary_classification()\n    \n    # ROC curve\n    roc_curve_analysis(X_test, y_test, y_pred_proba)\n    \n    # Multiclass classification\n    multiclass_classification()\n    \n    # Regularization comparison\n    regularization_comparison()\n    \n    # Decision boundary\n    decision_boundary_visualization()\n    \n    # Probability analysis\n    probability_analysis()\n    \n    # Cross-validation\n    cross_validation()\n    \n    # Feature coefficients\n    feature_coefficients()\n    \n    print(\"\\n\" + \"=\" * 50)\n    print(\"Lab 10 Complete!\")\n    print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}